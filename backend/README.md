<h1 align="center">JuriAssist - Backend</h1>

<p align="center">
  <strong>API e servi√ßos de IA para o sistema JuriAssist de an√°lise de documentos jur√≠dicos</strong>
</p>

## üìã Sobre

O backend do JuriAssist √© respons√°vel por processar documentos jur√≠dicos, gerenciar o banco de dados e integrar com modelos de IA atrav√©s do Ollama para fornecer an√°lises e respostas sobre quest√µes legais.

## ‚ú® Funcionalidades

-   **Processamento de Documentos**: API para upload, armazenamento e processamento de documentos jur√≠dicos
-   **Integra√ß√£o com IA**: Utiliza√ß√£o do Ollama e LangChain para an√°lise de documentos e gera√ß√£o de respostas
-   **Banco de Dados**: Armazenamento de documentos, metadados e hist√≥rico de intera√ß√µes
-   **Vetoriza√ß√£o de Documentos**: Indexa√ß√£o vetorial de documentos para busca sem√¢ntica com Qdrant
-   **API RESTful**: Endpoints documentados com Swagger para integra√ß√£o com o frontend

## üöÄ Tecnologias

![Node.js](https://img.shields.io/badge/Node.js-0D1117?style=for-the-badge&logo=node.js&logoColor=339933&labelColor=0D1117)&nbsp;
![TypeScript](https://img.shields.io/badge/TypeScript-0D1117?style=for-the-badge&logo=typescript&logoColor=3178C6&labelColor=0D1117)&nbsp;
![Express](https://img.shields.io/badge/Express-0D1117?style=for-the-badge&logo=express&logoColor=FFFFFF&labelColor=0D1117)&nbsp;
![LangChain](https://img.shields.io/badge/LangChain-0D1117?style=for-the-badge&logo=chainlink&logoColor=375BD2&labelColor=0D1117)&nbsp;
![Ollama](https://img.shields.io/badge/Ollama-0D1117?style=for-the-badge&logo=llama&logoColor=FFFFFF&labelColor=0D1117)&nbsp;
![Qdrant](https://img.shields.io/badge/Qdrant-0D1117?style=for-the-badge&logo=database&logoColor=FFFFFF&labelColor=0D1117)&nbsp;
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-0D1117?style=for-the-badge&logo=postgresql&logoColor=4169E1&labelColor=0D1117)&nbsp;
![Docker](https://img.shields.io/badge/Docker-0D1117?style=for-the-badge&logo=docker&logoColor=2496ED&labelColor=0D1117)&nbsp;
![Swagger](https://img.shields.io/badge/Swagger-0D1117?style=for-the-badge&logo=swagger&logoColor=85EA2D&labelColor=0D1117)&nbsp;

## ‚ö†Ô∏è Requisitos Importantes

Para executar o backend localmente, voc√™ precisar√°:

1. [Docker](https://www.docker.com/products/docker-desktop/) - Para gerenciar containers
2. [Ollama](https://ollama.com) - **√â NECESS√ÅRIO baixar e instalar o Ollama** para executar os modelos de IA localmente

## üì• Download do Projeto

Baixe o projeto em seu computador atrav√©s do comando:

```bash
https://github.com/anthonyDev01/JuriAssist.git
```

**ou**

1. Clique em `<> Code`.
2. Fa√ßa o download do arquivo ZIP.
3. Abra o seu explorador de arquivos na localiza√ß√£o da instala√ß√£o.
4. Extraia o arquivo ZIP.

## üîÑ Instala√ß√£o e Execu√ß√£o

1. Navegue at√© a pasta do backend:
   ```bash
   cd juriAssist/backend
   ```
2. Execute o comando para construir os containers Docker:
   ```bash
   docker-compose build
   ```

3. Execute o comando para iniciar os containers:
   ```bash
   docker-compose up -d
   ```

Este comando iniciar√° todos os servi√ßos necess√°rios:

-   API Node.js com Express
-   Banco de dados PostgreSQL
-   Servi√ßo Qdrant para busca vetorial
-   Integra√ß√£o com Ollama (que deve estar instalado em sua m√°quina)

> ‚ö†Ô∏è **Aten√ß√£o**: A instala√ß√£o do Ollama pode levar cerca de 10 minutos dependendo da sua velocidade de internet.

## üåê Documenta√ß√£o da API

A documenta√ß√£o da API est√° dispon√≠vel atrav√©s do Swagger UI:

```
http://localhost:3000/swagger
```

Atrav√©s desta interface, voc√™ pode explorar e testar todos os endpoints dispon√≠veis.

## üìä Estrutura do Banco de Dados

O sistema utiliza PostgreSQL para armazenar:

-   Registro de atividades
-   Hist√≥rico de intera√ß√µes com a IA
-   Configura√ß√µes do sistema

## üîç Busca Vetorial

O sistema utiliza Qdrant para indexa√ß√£o e busca vetorial de documentos, permitindo:

-   Busca sem√¢ntica em documentos
-   Recupera√ß√£o de contexto relevante para as perguntas do usu√°rio
-   Melhoria na precis√£o das respostas da IA

## ü§ñ Modelos de IA

O sistema utiliza Ollama para executar modelos de IA localmente, garantindo:

-   Privacidade dos dados
-   Processamento local de documentos sens√≠veis
-   Personaliza√ß√£o das respostas para o contexto jur√≠dico

## üîß Configura√ß√£o de Modelos

Por padr√£o, o sistema est√° configurado para utilizar o modelo Llama 3 8B, mas voc√™ pode configurar outros modelos dispon√≠veis no Ollama conforme sua necessidade.

